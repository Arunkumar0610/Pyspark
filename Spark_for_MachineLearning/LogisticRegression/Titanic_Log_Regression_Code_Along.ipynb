{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioJF8B9uccHh",
        "outputId": "ae731d43-0e35-4e41-baf7-d821280221c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=1f48b0e377b60f42b4412777af4fba656dd71446f6b6d225731e829424ce08cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Code Along\n",
        "This is a code along of the famous titanic dataset, its always nice to start off with this dataset because it is an example you will find across pretty much every data analysis language."
      ],
      "metadata": {
        "id": "ilrXnHxxb_7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "GdWGzr7PcYue"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('myproj').getOrCreate()"
      ],
      "metadata": {
        "id": "dAvEp0rjc9Xy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.csv('/content/sample_data/titanic.csv',inferSchema=True,header=True)"
      ],
      "metadata": {
        "id": "opxNSccedIuE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3BNk796dTlZ",
        "outputId": "15154069-3aa0-4cf1-d633-46944b454950"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNe7vC3rde8Z",
        "outputId": "14b16390-23a8-4ef9-ada1-46d1ca04c6b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PassengerId',\n",
              " 'Survived',\n",
              " 'Pclass',\n",
              " 'Name',\n",
              " 'Sex',\n",
              " 'Age',\n",
              " 'SibSp',\n",
              " 'Parch',\n",
              " 'Ticket',\n",
              " 'Fare',\n",
              " 'Cabin',\n",
              " 'Embarked']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mycols=df.select(['Survived',\n",
        " 'Pclass',\n",
        " 'Sex',\n",
        " 'Age',\n",
        " 'SibSp',\n",
        " 'Parch',\n",
        " 'Fare',\n",
        " 'Embarked'])"
      ],
      "metadata": {
        "id": "z8EcV5NydiTO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_final_data=mycols.na.drop()"
      ],
      "metadata": {
        "id": "vdjKm-bRd-ZB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with Categorical Columns\n",
        "Let's break this down into multiple steps to make it all clear."
      ],
      "metadata": {
        "id": "Mx5DVMPQcLMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer)"
      ],
      "metadata": {
        "id": "397kOb0lcZhn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_indexer=StringIndexer(inputCol='Sex',outputCol='SexIndex')\n",
        "#A B C\n",
        "#0 1 2\n",
        "#ONE HOT ENCODER\n",
        "#KEY A  B C\n",
        "#Example A\n",
        "#[1 , 0, 0]\n",
        "gender_encoder=OneHotEncoder(inputCol='SexIndex',outputCol='SexVec')"
      ],
      "metadata": {
        "id": "mV1KT1fOeWkp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embark_indexer=StringIndexer(inputCol='Embarked',outputCol='EmbarkedIndex')\n",
        "embark_encoder=OneHotEncoder(inputCol='EmbarkedIndex',outputCol='EmbarkedVec')"
      ],
      "metadata": {
        "id": "Gk4Ld4uufdhU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler=VectorAssembler(inputCols=['Pclass',\n",
        " 'SexVec',\n",
        " 'EmbarkedVec',\n",
        " 'Age',\n",
        " 'SibSp',\n",
        " 'Parch',\n",
        " 'Fare'\n",
        " ],outputCol='features')"
      ],
      "metadata": {
        "id": "Ty__eGqRf9aW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "metadata": {
        "id": "Nz9lFap4gbbG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipelines\n",
        "Let's see an example of how to use pipelines (we'll get a lot more practice with these later!)"
      ],
      "metadata": {
        "id": "jWuz9oxrcVXP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FvBTK1abb7N9"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_titanic=LogisticRegression(featuresCol='features',labelCol='Survived')"
      ],
      "metadata": {
        "id": "6EGVJlpJgh2R"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline=Pipeline(stages=[gender_indexer,embark_indexer,\n",
        "                          gender_encoder,embark_encoder,\n",
        "                          assembler,logreg_titanic])"
      ],
      "metadata": {
        "id": "VdYjAjjUg2oe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data=my_final_data.randomSplit([0.7,0.3])"
      ],
      "metadata": {
        "id": "Se6JbKZ5hHQu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model=pipeline.fit(train_data)"
      ],
      "metadata": {
        "id": "ahKqwhMDhWFY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results=fit_model.transform(test_data)"
      ],
      "metadata": {
        "id": "VYLQAU9whbDG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "metadata": {
        "id": "QjCAqYHzh65B"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_eval=BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='Survived')"
      ],
      "metadata": {
        "id": "BDkdyJthiFl5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.select('Survived','prediction').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNReasUkiSqj",
        "outputId": "926ed9a3-c487-4c7c-a012-83c78755f8bc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+\n",
            "|Survived|prediction|\n",
            "+--------+----------+\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       0.0|\n",
            "|       0|       1.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUC=my_eval.evaluate(results)"
      ],
      "metadata": {
        "id": "LaBC00_TiaEf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQqXWS9IiiyQ",
        "outputId": "0e8ae7ce-38cc-4d4a-dad5-ac7e7134f247"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7720588235294118"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}